# HW07 – Report

> Файл: `homeworks/HW07/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset 01

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: 8 числовых (f01-f08)
- Пропуски: нет
- "Подлости" датасета: разные шкалы признаков, что требует обязательного масштабирования

### 1.2 Dataset 02

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: 3 числовых (x1, x2, z_noise)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров, наличие шумового признака z_noise

### 1.3 Dataset 04

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000, 33)
- Признаки: 30 числовых (n01-n30) + 2 категориальных (cat_a, cat_b)
- Пропуски: да, около 2% в числовых признаках
- "Подлости" датасета: высокая размерность, пропуски в данных, категориальные признаки требующие кодирования

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: для всех датасетов применялось масштабирование числовых признаков (StandardScaler); для датасета 04 дополнительно обработка пропусков (SimpleImputer) и кодирование категориальных признаков (OneHotEncoder)
- Поиск гиперпараметров:
  - для KMeans: k от 2 до 20, выбор по максимуму silhouette_score
  - для DBSCAN: eps на основе k-distance plot, min_samples от 5 до 20, выбор по максимуму silhouette_score
  - для Agglomerative: k от 2 до 20, linkage=['ward', 'complete', 'average'], выбор по максимуму silhouette_score
- Метрики: silhouette_score (выше лучше), davies_bouldin_score (ниже лучше), calinski_harabasz_score (выше лучше); для DBSCAN метрики рассчитывались только на не-шумовых точках
- Визуализация: PCA(2D) для лучших решений каждого датасета, графики подбора параметров (silhouette vs k/eps)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k` от 2 до 20, фиксировали `random_state=42`, `n_init=10`)
- Для датасета 01: DBSCAN (`eps` от 0.3 до 1.1, `min_samples`=[5,10,15,20])
- Для датасета 02: AgglomerativeClustering (`k` от 2 до 20, `linkage`=['ward','complete','average'])
- Для датасета 04: DBSCAN (`eps` от 1.0 до 3.0, `min_samples`=[5,10,15])

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset 01

- Лучший метод и параметры: KMeans, k=2
- Метрики (silhouette / DB / CH): 0.522 / 0.685 / 11787
- Если был DBSCAN: доля шума и комментарий: DBSCAN нашел кластеры с некоторым шумом, но KMeans показал лучшие метрики
- Коротко: почему это решение выглядит разумным: данные имеют четкую структуру из 2 кластеров со сферической формой, что идеально подходит для KMeans

### 4.2 Dataset 02

- Лучший метод и параметры: Agglomerative, k=2, linkage='average'
- Метрики (silhouette / DB / CH): 0.420 / 0.879 / 395
- Коротко: нелинейная структура данных лучше подходит для иерархической кластеризации, особенно с linkage='average'

### 4.3 Dataset 04

- Лучший метод и параметры: DBSCAN, eps=2.0, min_samples=10
- Метрики (silhouette / DB / CH): 0.508 / 0.823 / 3867
- Если был DBSCAN: доля шума и комментарий: DBSCAN выделил 49.2% точек как шум, что полезно для выявления выбросов в данных
- Коротко: высокая размерность и смешанные типы данных требуют аккуратного подхода, DBSCAN лучше справился с выделением шума

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? KMeans плохо работает с нелинейными формами кластеров и шумом (как в датасете 02)
- Где DBSCAN/иерархическая кластеризация выигрывают и почему? DBSCAN хорошо находит шум и кластеры произвольной формы; иерархическая кластеризация лучше справляется с нелинейными структурами
- Что сильнее всего влияло на результат: масштабирование (критично для distance-based методов), форма кластеров (сферическая vs произвольная), наличие шума и выбросов

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans на датасете 01 с разными random_state, оценка похожести разбиений с помощью ARI
- Что получилось: средний ARI 0.967, стандартное отклонение 0.015, минимальный ARI 0.949, максимальный ARI 0.987
- Вывод: решение очень устойчиво (низкая вариативность результатов)

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры: анализ средних значений признаков в каждом кластере, визуализация через PCA
- Выводы: кластеры различаются по основным характеристикам, что позволяет их содержательно интерпретировать

## 6. Conclusion

1. Освоил различия между методами кластеризации: KMeans для сферических кластеров, DBSCAN для плотностных структур с шумом, иерархическая кластеризация для нелинейных форм
2. Научился корректному препроцессингу: масштабирование обязательно, обработка пропусков и кодирование категориальных признаков
3. Освоил внутренние метрики качества: silhouette, Davies-Bouldin, Calinski-Harabasz с правильной интерпретацией
4. Научился визуализировать результаты через PCA и графики подбора параметров
5. Понял важность проверки устойчивости решений в unsupervised-задачах
6. В целом, unsupervised-кластеризация требует тщательного подбора параметров и интерпретации результатов